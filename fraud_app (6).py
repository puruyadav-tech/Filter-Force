# -*- coding: utf-8 -*-
"""fraud_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xa9IT3yQfQa6fl9GZlMPAGdHdPaz4Qu8
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import io
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from imblearn.over_sampling import SMOTE
from scipy.sparse import hstack
import matplotlib.pyplot as plt

st.set_page_config(page_title="üéØ Fraud Job Detector", layout="wide")

st.markdown("""
    <style>
    .main {
        background-color: #f4f9fd;
        color: #333333;
    }
    .block-container {
        padding: 2rem;
    }
    h1 {
        text-align: center;
        color: #0077b6;
    }
    .css-1d391kg p {
        text-align: center;
        font-size: 18px;
    }
    .sidebar .sidebar-content {
        background-color: #ffffff;
        padding: 2rem;
    }
    .left-panel {
        background-color: #e3f2fd;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0px 0px 10px rgba(0,0,0,0.1);
        border: 2px solid #90e0ef;
    }
    .left-panel h3 {
        color: #0077b6;
        margin-top: 0;
    }
    .emoji-header {
        font-size: 48px;
        text-align: center;
    }
    .animated-icon {
        width: 32px;
        vertical-align: middle;
        margin-right: 8px;
        animation: float 1.5s ease-in-out infinite;
    }
    @keyframes float {
        0% { transform: translatey(0px); }
        50% { transform: translatey(-5px); }
        100% { transform: translatey(0px); }
    }
    ul li {
        background-color: #dff6ff;
        margin: 6px 0;
        padding: 6px 10px;
        border-radius: 6px;
        border-left: 4px solid #00b4d8;
        font-size: 15px;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="emoji-header">üïµÔ∏è‚Äç‚ôÇÔ∏è</div>
<h1>AI-Powered Job Fraud Detection</h1>
<p style='text-align: center;'>Detect potentially fraudulent job postings using intelligent machine learning.</p>
<hr style='margin-top: 0;'>
""", unsafe_allow_html=True)

col1, col2 = st.columns([1.2, 2.8])
with col1:
    st.markdown("""
    <div class="left-panel">
        <h3><img src="https://cdn-icons-png.flaticon.com/512/126/126472.png" class="animated-icon"> Instructions</h3>
        <ul>
            <li>üì§ <b>Upload</b> a job postings CSV file</li>
            <li>ü§ñ The AI model will <b>predict</b> fraudulent listings</li>
            <li>üì• <b>Download</b> the results with confidence scores</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/1828/1828884.png" class="animated-icon"> Alert Highlights</h3>
        <ul>
            <li>üìä Real-world training data</li>
            <li>üìö Text & behavioral features</li>
            <li>üîç Probabilistic predictions</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/1041/1041916.png" class="animated-icon"> Tools</h3>
        <ul>
            <li>üß† XGBoost ML</li>
            <li>üìù TF-IDF Vectorization</li>
            <li>üìà SMOTE Class Balancing</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/561/561127.png" class="animated-icon"> Contact</h3>
        <p><small>support@fraudjobdetector.ai</small></p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    uploaded_file = st.file_uploader("üì§ Upload a CSV file for prediction", type="csv")

    @st.cache_data
    def load_data():
        file_id = "1oxygynnHOAU3NU3S8xHRdBS9WA_K1E7y"
        url = f"https://drive.google.com/uc?id={file_id}"
        try:
            response = requests.get(url)
            response.raise_for_status()
            train_df = pd.read_csv(io.BytesIO(response.content))
        except Exception as e:
            st.error(f"Error loading training data from Google Drive: {e}")
            train_df = pd.DataFrame()
        return train_df

    @st.cache_data
    def prepare(df):
        df = df.copy()
        for col in ['title', 'description', 'requirements', 'company_profile']:
            if col not in df.columns:
                df[col] = ''
            else:
                df[col] = df[col].fillna('')
        df['email'] = df['email'].fillna('') if 'email' in df.columns else [''] * len(df)
        df['text'] = df['title'] + ' ' + df['description'] + ' ' + df['requirements'] + ' ' + df['company_profile']
        df['desc_len'] = df['description'].apply(len)
        df['word_count'] = df['description'].apply(lambda x: len(x.split()))
        df['num_digits_in_title'] = df['title'].apply(lambda x: sum(c.isdigit() for c in x))
        df['has_profile'] = (df['company_profile'] != '').astype(int)
        suspicious_words = ['money', 'wire', 'bitcoin', 'transfer', 'click']
        df['suspicious_terms'] = df['description'].apply(lambda x: int(any(term in x.lower() for term in suspicious_words)))
        df['email_domain'] = df['email'].apply(lambda x: x.split('@')[-1] if '@' in x else '')
        df['free_email'] = df['email_domain'].isin(['gmail.com', 'yahoo.com', 'hotmail.com']).astype(int)
        return df

    @st.cache_resource
    def train_model(train_df):
        if train_df.empty:
            st.warning("Training data not loaded. Model training skipped.")
            return None, None, 0.5
        X = train_df[['text', 'desc_len', 'word_count', 'num_digits_in_title', 'has_profile', 'suspicious_terms', 'free_email']]
        y = train_df['fraudulent']
        tfidf = TfidfVectorizer(max_features=5000, stop_words='english')
        X_tfidf = tfidf.fit_transform(X['text'])
        X_combined = hstack([X_tfidf, X.drop(columns='text').values])
        X_train, X_val, y_train, y_val = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)
        X_res, y_res = SMOTE(random_state=42).fit_resample(X_train, y_train)
        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
        model.fit(X_res, y_res)
        val_probs = model.predict_proba(X_val)[:, 1]
        target_fraud_rate = 0.052
        sorted_probs = np.sort(val_probs)[::-1]
        cut_index = int(len(sorted_probs) * target_fraud_rate)
        best_threshold = sorted_probs[cut_index] if cut_index < len(sorted_probs) else 0.5
        return model, tfidf, best_threshold

    train_df = load_data()
    if not train_df.empty:
        train_df = prepare(train_df)
    model, tfidf, best_threshold = train_model(train_df)

    if uploaded_file is not None:
        try:
            test_df = pd.read_csv(uploaded_file)
            test_df = prepare(test_df)
            if model is not None and tfidf is not None:
                X_test = test_df[['text', 'desc_len', 'word_count', 'num_digits_in_title', 'has_profile', 'suspicious_terms', 'free_email']]
                X_test_tfidf = tfidf.transform(X_test['text'])
                X_test_combined = hstack([X_test_tfidf, X_test.drop(columns='text').values])
                test_df['fraud_probability'] = model.predict_proba(X_test_combined)[:, 1]
                test_df['fraud_predicted'] = (test_df['fraud_probability'] >= best_threshold).astype(int)
                st.success("‚úÖ Predictions generated successfully!")
                st.markdown("### üìã Job Predictions")
                st.dataframe(test_df[['title', 'location', 'fraud_probability', 'fraud_predicted']].sort_values(by='fraud_probability', ascending=False), use_container_width=True)
                st.download_button("üì• Download Results as CSV", data=test_df.to_csv(index=False).encode(), file_name="fraud_predictions.csv", mime="text/csv")
                st.markdown("### üìä Probability Distribution")
                fig, ax = plt.subplots()
                ax.hist(test_df['fraud_probability'], bins=20, color='#0077b6', edgecolor='white')
                ax.set_xlabel("Fraud Probability")
                ax.set_ylabel("Job Count")
                st.pyplot(fig)
                st.markdown("### üßÆ Fraud Prediction Breakdown")
                fraud_counts = test_df['fraud_predicted'].value_counts()
                labels = ['Not Fraud', 'Fraud']
                sizes = [fraud_counts.get(0, 0), fraud_counts.get(1, 0)]
                fig2, ax2 = plt.subplots()
                ax2.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['#90e0ef', '#ff6b6b'], startangle=90)
                ax2.axis('equal')
                st.pyplot(fig2)
            else:
                st.warning("Model not loaded. Cannot generate predictions.")
        except Exception as e:
            st.error(f"Error processing uploaded file: {e}")
    else:
        st.info("üëà Upload a CSV file from the left panel to begin analysis.")

st.markdown("---")
st.markdown("<small>üöÄ Developed with ‚ù§Ô∏è using Streamlit</small>", unsafe_allow_html=True)