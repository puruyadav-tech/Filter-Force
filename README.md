# fraud-detector-app
ğŸ” Job Fraud Detector | Anveshan Hackathon Project An ML-powered Streamlit web app that detects fake job listings using natural language processing, feature engineering, and XGBoost. Includes real-time predictions, SHAP explanations, search, filtering, and CSV export â€” built to protect job seekers from online scams
https://drive.google.com/file/d/1oxygynnHOAU3NU3S8xHRdBS9WA_K1E7y/view?usp=sharing

 Fraud Detector: Smart Job Scam Detection System
ğŸ§  Project Overview
Online job platforms are frequently targeted by scammers. These fake job listings waste applicantsâ€™ time and put their personal information at risk.

This project builds a machine learning pipeline that automatically detects fraudulent job listings and presents insights in a Streamlit-powered interactive dashboard.

ğŸ¯ Problem Statement
Develop a system to classify job listings as fraudulent or genuine using structured and unstructured data. Display predictions and insights in an intuitive dashboard.

ğŸš€ Automatic Job Fraud Detection
Classifies job listings as real or fake using advanced machine learning techniques.

ğŸ§  Hybrid Feature Engineering
Combines TF-IDF text vectors with structured numeric features:

-Description length & word count

-Suspicious keywords (e.g., money, bitcoin)

-Free email domain indicators (e.g., gmail.com, yahoo.com)

-Digit count in job titles

ğŸŒ² XGBoost Classifier for Accuracy & Speed

Leverages the power of XGBoost â€” a high-performance gradient boosting algorithm â€” for fast training and accurate predictions.

âš–ï¸ Class Imbalance Handling with SMOTE
Uses SMOTE oversampling to improve detection of rare fraudulent cases without overfitting.

ğŸ§ª F1-Optimized Threshold Tuning

Dynamically selects the best threshold using precision-recall curve to maximize the F1-score â€” ideal for imbalanced data.

ğŸ“Š Visual Analytics Dashboard

-Histogram of fraud probabilities

-Pie chart of predicted real vs. fake listings

-Threshold vs. F1-score visualization

-SHAP summary plots for feature importance

ğŸ” Explainable AI with SHAP

-Visualize top contributing features

-Interpret individual predictions

-Enhance transparency and trust in model decisions

âœ‰ï¸ High-Risk Job Alert System

Automatically flags listings with fraud probability â‰¥ 0.8 and supports email alerts via SMTP integration.

ğŸ”— Unified Text + Numeric Feature Pipeline

Combines TF-IDF matrix with custom features using scipy.sparse.hstack for seamless model input.

âš¡ Deployment-Ready with Streamlit

Integrated with a user-friendly Streamlit interface for real-time fraud prediction and insights.

ğŸ› ï¸ Technologies Used


| Area          | Tools/Libraries                      |
| ------------- | ------------------------------------ |
| Data Handling | `pandas`, `numpy`                    |
| Modeling      | `XGBoost`, `SMOTE`                   |
| NLP           | `TfidfVectorizer`                    |
| Evaluation    | `F1-score`, `precision-recall` curve |
| Visualization | `matplotlib`, `seaborn`, `SHAP`      |
| Web Dashboard | `Streamlit`                          |
| Deployment    | `Streamlit Cloud`                    |


ğŸ§¾ Setup Instructions

![image](https://github.com/user-attachments/assets/76357276-f33e-4ec6-abcf-42a88bea3ca9)

â€¢ pandas and numpy: Used for handling structured data and numerical operations.

â€¢ matplotlib.pyplot and seaborn: Used for plotting graphs and visualizing distributions and model results.

â€¢ TfidfVectorizer: Converts text into numerical features based on frequency and importance.

â€¢ RandomForestClassifier: (Though unused here) A machine learning model. You used XGBClassifier instead.

â€¢ XGBClassifier: An optimized version of gradient-boosted trees, very powerful for tabular data.

â€¢ train_test_split: Splits data into training and validation sets.

â€¢ classification_report, confusion_matrix, f1_score, etc.: Used to evaluate model performance.

â€¢ SMOTE: Balances the dataset by generating synthetic examples for the minority class (fraudulent jobs).

â€¢ shap: Helps explain the modelâ€™s predictions and shows which features are most important.

â€¢ warnings.filterwarnings("ignore"): Suppresses warnings for clean output.

![image](https://github.com/user-attachments/assets/bbaa63e7-e7f2-48cf-b056-39a4b1bdac1c)

â€¢ Reading CSV files into pandas DataFrames.

â€¢ on_bad_lines='skip' ensures any corrupted lines or format errors are skipped rather than crashing the program.

![image](https://github.com/user-attachments/assets/729bac06-9b45-4aa4-90cf-bc0602c47fcd)

ğŸ§¹ Dataset Preparation & Feature Engineering
To ensure robust and consistent model training, we preprocess and enrich the dataset through a series of thoughtful transformations:

1. âœ… Safe Copy of the Data
We begin by copying the input DataFrame to avoid modifying the original data. This is a best practice for all preprocessing pipelines.

2. ğŸ§¾ Validate and Clean Text Columns
We ensure key textual columns (title, description, requirements, company_profile) exist. If missing, they're created and filled with empty strings to avoid errors during vectorization.

3. ğŸ“§ Clean the Email Column
If the email field exists, we replace all missing values with blank strings to maintain formatting and prevent errors during feature extraction.

4. ğŸ“š Merge Text for TF-IDF
We combine all main text fields into a unified full_text column, which is used to generate TF-IDF features. This leverages the entire job listing content for better text-based learning.

5. ğŸ§  Generate Custom Features
We engineer several insightful features to detect fraud patterns:

desc_len: Length of the job description (in characters).

word_count: Number of words in the description.

num_digits_in_title: Count of numerical digits in the job title (e.g., â€œEarn $5000â€).

has_profile: Boolean flag â€” does the company provide a profile?

suspicious_terms: Checks for keywords like "bitcoin", "transfer", "click", "money", etc., common in scams.

6. ğŸ“¬ Email-Based Features
email_domain: Extracted from the email (e.g., gmail.com, company.com).

free_email: Flags whether the domain belongs to a free provider (like gmail, yahoo, etc.), often used in fake listings.

7. ğŸ”„ Consistency Across Datasets
We apply the same transformation function to both training and test datasets. This guarantees consistent features during model training and inference.






