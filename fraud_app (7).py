# -*- coding: utf-8 -*-
"""fraud_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xa9IT3yQfQa6fl9GZlMPAGdHdPaz4Qu8
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import io
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from imblearn.over_sampling import SMOTE
from scipy.sparse import hstack
import matplotlib.pyplot as plt

st.set_page_config(page_title="ğŸ¯ Fraud Job Detector", layout="wide")

st.markdown("""
    <style>
    body {
        animation: backgroundFade 3s ease-in-out forwards;
        background: linear-gradient(to right, #f4f9fd, #d0eefe);
    }
    @keyframes backgroundFade {
        0% { background: #f4f9fd; }
        100% { background: linear-gradient(to right, #f4f9fd, #d0eefe); }
    }
    .main {
        color: #333333;
    }
    .block-container {
        padding: 2rem;
    }
    h1 {
        text-align: center;
        color: #0077b6;
    }
    .css-1d391kg p {
        text-align: center;
        font-size: 18px;
    }
    .sidebar .sidebar-content {
        background-color: #ffffff;
        padding: 2rem;
    }
    .left-panel {
        background-color: #e3f2fd;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0px 0px 10px rgba(0,0,0,0.1);
        border: 2px solid #90e0ef;
    }
    .right-panel {
        background-color: #ffffff;
        padding: 2rem;
        border-radius: 12px;
        border: 2px solid #caf0f8;
        box-shadow: 0px 0px 10px rgba(0,0,0,0.05);
    }
    .left-panel h3 {
        color: #0077b6;
        margin-top: 0;
    }
    .emoji-header {
        font-size: 48px;
        text-align: center;
    }
    .animated-icon {
        width: 32px;
        vertical-align: middle;
        margin-right: 8px;
        animation: float 1.5s ease-in-out infinite;
    }
    @keyframes float {
        0% { transform: translatey(0px); }
        50% { transform: translatey(-5px); }
        100% { transform: translatey(0px); }
    }
    ul li {
        background-color: #dff6ff;
        margin: 6px 0;
        padding: 6px 10px;
        border-radius: 6px;
        border-left: 4px solid #00b4d8;
        font-size: 15px;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="emoji-header">ğŸ•µï¸â€â™‚ï¸</div>
<h1>AI-Powered Job Fraud Detection</h1>
<p style='text-align: center;'>Detect potentially fraudulent job postings.</p>
<hr style='margin-top: 0;'>
""", unsafe_allow_html=True)

col1, col2 = st.columns([1.2, 2.8])
with col1:
    st.markdown("""
    <div class="left-panel">
        <h3><img src="https://cdn-icons-png.flaticon.com/512/126/126472.png" class="animated-icon"> Instructions</h3>
        <ul>
            <li>ğŸ“¤ <b>Upload</b> a job postings CSV file</li>
            <li>ğŸ¤– The AI model will <b>predict</b> fraudulent listings</li>
            <li>ğŸ“¥ <b>Download</b> the results with confidence scores</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/1828/1828884.png" class="animated-icon"> Alert Highlights</h3>
        <ul>
            <li>ğŸ“Š Real-world training data</li>
            <li>ğŸ“š Text & behavioral features</li>
            <li>ğŸ” Probabilistic predictions</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/1041/1041916.png" class="animated-icon"> Tools</h3>
        <ul>
            <li>ğŸ§  XGBoost ML</li>
            <li>ğŸ“ TF-IDF Vectorization</li>
            <li>ğŸ“ˆ SMOTE Class Balancing</li>
        </ul>
        <hr>
        <h3><img src="https://cdn-icons-png.flaticon.com/512/561/561127.png" class="animated-icon"> Contact</h3>
        <p><small>support@fraudjobdetector.ai</small></p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div class="right-panel">
        <h3>Main App Content Goes Here</h3>
        <p>This panel can display results, upload widgets, charts, etc.</p>
    </div>
    """, unsafe_allow_html=True)

st.sidebar.markdown("""
## ğŸ§° Instructions
ğŸ“¤ **Upload** a job postings CSV file
ğŸ¤– The AI model will **predict** fraudulent listings
ğŸ“¥ **Download** the results with confidence scores

---
## ğŸš¨ Alert Highlights
ğŸ“Š Model trained on real-world job data
ğŸ“š Uses text features & behavioral signals
ğŸ” Predictions are probabilistic â€” not absolute

---
## ğŸ› ï¸ Tools
ğŸ§  Machine Learning with XGBoost
ğŸ“ Text Vectorization with TF-IDF
ğŸ“ˆ Class Balancing with SMOTE
""")

@st.cache_data
def load_data():
    file_id = "1oxygynnHOAU3NU3S8xHRdBS9WA_K1E7y"
    url = f"https://drive.google.com/uc?id={file_id}"

    try:
        response = requests.get(url)
        response.raise_for_status()
        train_df = pd.read_csv(io.BytesIO(response.content))
    except Exception as e:
        st.error(f"Error loading training data from Google Drive: {e}")
        train_df = pd.DataFrame()

    return train_df

@st.cache_data
def prepare(df):
    df = df.copy()
    for col in ['title', 'description', 'requirements', 'company_profile']:
        if col not in df.columns:
            df[col] = ''
        else:
            df[col] = df[col].fillna('')

    if 'email' in df.columns:
        df['email'] = df['email'].fillna('')
    else:
        df['email'] = [''] * len(df)

    df['text'] = (
        df['title'] + ' ' +
        df['description'] + ' ' +
        df['requirements'] + ' ' +
        df['company_profile']
    )

    df['desc_len'] = df['description'].apply(len)
    df['word_count'] = df['description'].apply(lambda x: len(x.split()))
    df['num_digits_in_title'] = df['title'].apply(lambda x: sum(c.isdigit() for c in x))
    df['has_profile'] = (df['company_profile'] != '').astype(int)

    suspicious_words = ['money', 'wire', 'bitcoin', 'transfer', 'click']
    df['suspicious_terms'] = df['description'].apply(
        lambda x: int(any(term in x.lower() for term in suspicious_words))
    )

    df['email_domain'] = df['email'].apply(lambda x: x.split('@')[-1] if '@' in x else '')
    df['free_email'] = df['email_domain'].isin(['gmail.com', 'yahoo.com', 'hotmail.com']).astype(int)

    return df

@st.cache_resource
def train_model(train_df):
    if train_df.empty:
        st.warning("Training data not loaded. Model training skipped.")
        return None, None, 0.5

    X = train_df[['text', 'desc_len', 'word_count', 'num_digits_in_title', 'has_profile', 'suspicious_terms', 'free_email']]
    y = train_df['fraudulent']
    tfidf = TfidfVectorizer(max_features=5000, stop_words='english')
    X_tfidf = tfidf.fit_transform(X['text'])
    X_combined = hstack([X_tfidf, X.drop(columns='text').values])
    X_train, X_val, y_train, y_val = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)
    X_res, y_res = SMOTE(random_state=42).fit_resample(X_train, y_train)
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    model.fit(X_res, y_res)
    val_probs = model.predict_proba(X_val)[:, 1]
    p, r, thresholds = precision_recall_curve(y_val, val_probs)
    f1s = 2 * p * r / (p + r + 1e-6)
    best_threshold = thresholds[np.argmax(f1s)]
    return model, tfidf, best_threshold

train_df = load_data()
if not train_df.empty:
    train_df = prepare(train_df)
model, tfidf, best_threshold = train_model(train_df)

uploaded_file = st.sidebar.file_uploader("ğŸ“¤ Upload a CSV file for prediction", type="csv")
if uploaded_file is not None:
    try:
        test_df = pd.read_csv(uploaded_file)
        test_df = prepare(test_df)
        if model is not None and tfidf is not None:
            X_test = test_df[['text', 'desc_len', 'word_count', 'num_digits_in_title', 'has_profile', 'suspicious_terms', 'free_email']]
            X_test_tfidf = tfidf.transform(X_test['text'])
            X_test_combined = hstack([X_test_tfidf, X_test.drop(columns='text').values])
            test_df['fraud_probability'] = model.predict_proba(X_test_combined)[:, 1]
            test_df['fraud_predicted'] = (test_df['fraud_probability'] >= best_threshold).astype(int)

            st.success("âœ… Predictions generated successfully!")

            st.markdown("### ğŸ“‹ Job Predictions")
            st.dataframe(
                test_df[['title', 'location', 'fraud_probability', 'fraud_predicted']].sort_values(by='fraud_probability', ascending=False),
                use_container_width=True
            )

            st.download_button(
                "ğŸ“¥ Download Results as CSV",
                data=test_df.to_csv(index=False).encode(),
                file_name="fraud_predictions.csv",
                mime="text/csv"
            )

            st.markdown("### ğŸ“Š Probability Distribution")
            fig, ax = plt.subplots()
            ax.hist(test_df['fraud_probability'], bins=20, color='#0077b6', edgecolor='white')
            ax.set_xlabel("Fraud Probability")
            ax.set_ylabel("Job Count")
            st.pyplot(fig)

            st.markdown("### ğŸ§® Fraud Prediction Breakdown")
            fraud_counts = test_df['fraud_predicted'].value_counts()
            labels = ['Not Fraud', 'Fraud']
            sizes = [fraud_counts.get(0, 0), fraud_counts.get(1, 0)]

            fig2, ax2 = plt.subplots()
            ax2.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['#90e0ef', '#ff6b6b'], startangle=90)
            ax2.axis('equal')
            st.pyplot(fig2)

        else:
            st.warning("Model not loaded. Cannot generate predictions.")
    except Exception as e:
        st.error(f"Error processing uploaded file: {e}")
else:
    st.info("ğŸ‘ˆ Upload a CSV file from the sidebar to begin analysis.")

st.markdown("---")
st.markdown("<small>ğŸš€ Developed with â¤ï¸ using Streamlit</small>", unsafe_allow_html=True)